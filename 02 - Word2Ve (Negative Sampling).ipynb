{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define some very simple data for understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "# Fetch sentences from the 'news' category of the Brown corpus\n",
    "corpus = brown.sents(categories='news') \n",
    "\n",
    "# Convert sentences into a list of words for each sentence\n",
    "corpus = [[word for word in sentence] for sentence in corpus]\n",
    "\n",
    "# Print the first sentence as a list of words\n",
    "print(corpus[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get word sequences and unique words\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocab = list(set(flatten(corpus)))\n",
    "\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numericalization\n",
    "word2index = {w: i for i, w in enumerate(vocab)}\n",
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab size\n",
    "voc_size = len(vocab)\n",
    "print(voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append UNK\n",
    "vocab.append('<UNK>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index['<UNK>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just in case we need to use\n",
    "index2word = {v:k for k, v in word2index.items()} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in corpus:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size, word_sequence):\n",
    "    \n",
    "    # Make skip gram of one size window\n",
    "    skip_grams = []\n",
    "    # loop each word sequence\n",
    "    # we starts from 1 because 0 has no context\n",
    "    # we stop at second last for the same reason\n",
    "    for sent in corpus:\n",
    "        for i in range(1, len(sent) - 1):\n",
    "            target = word2index[sent[i]]\n",
    "            context = [word2index[sent[i - 1]], word2index[sent[i + 1]]]\n",
    "            for w in context:\n",
    "                skip_grams.append([target, w])\n",
    "    \n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) #randomly pick without replacement\n",
    "        \n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams[i][0]])  # target, e.g., 2\n",
    "        random_labels.append([skip_grams[i][1]])  # context word, e.g., 3\n",
    "            \n",
    "    return np.array(random_inputs), np.array(random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the method\n",
    "batch_size = 2 # mini-batch size\n",
    "input_batch, target_batch = random_batch(batch_size, corpus)\n",
    "\n",
    "print(\"Input: \", input_batch)\n",
    "print(\"Target: \", target_batch)\n",
    "\n",
    "#we will convert them to tensor during training, so don't worry..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch.shape, target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Negative Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram distribution\n",
    "\n",
    "$$P(w)=U(w)^{3/4}/Z$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 0.001\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "word_count = Counter(flatten(corpus))\n",
    "num_total_words = sum([c for w, c in word_count.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count[',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_table = []\n",
    "\n",
    "for vo in vocab:\n",
    "    unigram_table.extend([vo] * int(((word_count[vo]/num_total_words)**0.75)/Z))\n",
    "\n",
    "Counter(unigram_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "def negative_sampling(targets, unigram_table, k):\n",
    "    batch_size = targets.size(0)\n",
    "    neg_samples = []\n",
    "    for i in range(batch_size):\n",
    "        nsample = []\n",
    "        target_index = targets[i].item()\n",
    "        while len(nsample) < k: # num of sampling\n",
    "            neg = random.choice(unigram_table)\n",
    "            if word2index[neg] == target_index:\n",
    "                continue\n",
    "            nsample.append(neg)\n",
    "        neg_samples.append(prepare_sequence(nsample, word2index).view(1, -1))\n",
    "    return torch.cat(neg_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch  = torch.Tensor(input_batch)\n",
    "target_batch = torch.LongTensor(target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neg = 3\n",
    "negative_sampling(target_batch, unigram_table, num_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model\n",
    "\n",
    "$$\\mathbf{J}_{\\text{neg-sample}}(\\mathbf{v}_c,o,\\mathbf{U})=-\\log(\\sigma(\\mathbf{u}_o^T\\mathbf{v}_c))-\\sum_{k=1}^K\\log(\\sigma(-\\mathbf{u}_k^T\\mathbf{v}_c))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipgramNegSampling(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super(SkipgramNegSampling, self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, emb_size) # center embedding\n",
    "        self.embedding_u = nn.Embedding(vocab_size, emb_size) # out embedding\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "                    \n",
    "    def forward(self, center_words, target_words, negative_words):\n",
    "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
    "        neg_embeds    = -self.embedding_u(negative_words) # [batch_size, num_neg, emb_size]\n",
    "        \n",
    "        positive_score = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "        \n",
    "        negative_score = neg_embeds.bmm(center_embeds.transpose(1, 2))\n",
    "        #[batch_size, k, emb_size] @ [batch_size, emb_size, 1] = [batch_size, k, 1]\n",
    "        \n",
    "        loss = self.logsigmoid(positive_score) + torch.sum(self.logsigmoid(negative_score), 1)\n",
    "                \n",
    "        return -torch.mean(loss)\n",
    "    \n",
    "    def prediction(self, inputs):\n",
    "        embeds = self.embedding_v(inputs)\n",
    "        \n",
    "        return embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size     = 2 # mini-batch size\n",
    "embedding_size = 2 #so we can later plot\n",
    "model          = SkipgramNegSampling(voc_size, embedding_size)\n",
    "num_neg        = 10 # num of negative sampling\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_sequence(seq, word2index):\n",
    "#     idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "#     return torch.LongTensor(idxs)\n",
    "\n",
    "# #use for the normalized term in the probability calculation\n",
    "# all_vocabs = prepare_sequence(list(vocab), word2index).expand(batch_size, len(vocab))  # [batch_size, voc_size]\n",
    "# all_vocabs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Training\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    input_batch, target_batch = random_batch(batch_size, corpus)\n",
    "    \n",
    "    #input_batch: [batch_size, 1]\n",
    "    input_batch = torch.LongTensor(input_batch)\n",
    "    \n",
    "    #target_batch: [batch_size, 1]\n",
    "    target_batch = torch.LongTensor(target_batch)\n",
    "    \n",
    "    #negs_batch:   [batch_size, num_neg]\n",
    "    negs_batch = negative_sampling(target_batch, unigram_table, num_neg)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    loss = model(input_batch, target_batch, negs_batch)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plotting the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's write a function to get embedding given a word\n",
    "def get_embed(word):\n",
    "    id_tensor = torch.LongTensor([word2index[word]])\n",
    "    v_embed = model.embedding_v(id_tensor)\n",
    "    u_embed = model.embedding_u(id_tensor) \n",
    "    word_embed = (v_embed + u_embed) / 2 \n",
    "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6,10))\n",
    "# for i, word in enumerate(vocab[:]): #loop each unique vocab\n",
    "#     x, y = get_embed(word)\n",
    "#     plt.scatter(x, y)\n",
    "#     plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cosine similarity\n",
    "\n",
    "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
    "\n",
    "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
    "\n",
    "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word-test_semantic.txt', 'r') as file:\n",
    "    # Read the entire file content\n",
    "    # dataset = file.read() \n",
    "    # print(dataset)\n",
    "\n",
    "    # Read the file line by line\n",
    "    # for line in file:\n",
    "    #     print(line.strip()) \n",
    "\n",
    "    # Read all lines into a list\n",
    "    data_sem = file.readlines()\n",
    "    print(data_sem)\n",
    "\n",
    "with open('word-test_syntactic.txt', 'r') as file:\n",
    "    # Read all lines into a list\n",
    "    data_syn = file.readlines()\n",
    "    print(data_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    cleaned_data = []\n",
    "    for line in data:\n",
    "        cleaned_line = line.strip()  # Remove leading/trailing whitespace, including \\n and \\t\n",
    "        cleaned_data.append(cleaned_line)\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "# usage:\n",
    "data_sem = clean_data(data_sem)\n",
    "print(data_sem)\n",
    "\n",
    "data_syn = clean_data(data_syn)\n",
    "print(data_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_analogies(file_data):\n",
    "    \"\"\"\n",
    "    Parse analogy datasets.\n",
    "    Each analogy should be in the format: word1 word2 word3 word4\n",
    "    \"\"\"\n",
    "    analogies = []\n",
    "    for line in file_data:\n",
    "        words = line.split()\n",
    "        if len(words) == 4:\n",
    "            analogies.append(tuple(words))\n",
    "    return analogies\n",
    "\n",
    "# Parse the datasets\n",
    "semantic_analogies = parse_analogies(data_sem)\n",
    "syntactic_analogies = parse_analogies(data_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntactic_analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(model, word2index, index2word, analogy):\n",
    "    word1, word2, word3, _ = analogy\n",
    "    if word1 not in word2index or word2 not in word2index or word3 not in word2index:\n",
    "        return '<UNK>'  # Return UNK if any word is out of vocabulary\n",
    "\n",
    "    word1_idx = torch.LongTensor([word2index[word1]])\n",
    "    word2_idx = torch.LongTensor([word2index[word2]])\n",
    "    word3_idx = torch.LongTensor([word2index[word3]])\n",
    "\n",
    "    # Get embeddings\n",
    "    word1_embed = model.embedding_v(word1_idx)\n",
    "    word2_embed = model.embedding_v(word2_idx)\n",
    "    word3_embed = model.embedding_v(word3_idx)\n",
    "\n",
    "    # Vector math: word2 - word1 + word3\n",
    "    target_vector = word2_embed - word1_embed + word3_embed\n",
    "\n",
    "    # Compute cosine similarity with all vocabulary embeddings\n",
    "    all_embeddings = model.embedding_v.weight.data\n",
    "    similarities = torch.nn.functional.cosine_similarity(target_vector, all_embeddings, dim=1)\n",
    "\n",
    "    # Find the index of the most similar word\n",
    "    predicted_idx = torch.argmax(similarities).item()\n",
    "    return index2word[predicted_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Accuracy calculation: semantic and syntactic_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(analogies, model, word2index, index2word):\n",
    "    \"\"\"\n",
    "    Calculate accuracy for a given set of analogies.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for analogy in analogies:\n",
    "        total += 1\n",
    "        predicted_word = predict_word(model, word2index, index2word, analogy)\n",
    "        if predicted_word.lower() == analogy[3].lower():\n",
    "            correct += 1\n",
    "\n",
    "    return correct / total if total > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate syntactic and semantic accuracies\n",
    "semantic_accuracy = calculate_accuracy(semantic_analogies, model, word2index, index2word)\n",
    "syntactic_accuracy = calculate_accuracy(syntactic_analogies, model, word2index, index2word)\n",
    "\n",
    "print(f\"Semantic Accuracy: {semantic_accuracy * 100:.2f}%\")\n",
    "print(f\"Syntactic Accuracy: {syntactic_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def parse_similarity_file(filepath):\n",
    "    word_pairs = []\n",
    "    human_scores = []\n",
    "\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            words = line.split()\n",
    "            if len(words) == 3:\n",
    "                word1, word2, score = words\n",
    "                word_pairs.append((word1, word2))\n",
    "                human_scores.append(float(score))\n",
    "    \n",
    "    return word_pairs, human_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_model_similarity(model, word2index, word_pairs):\n",
    "    similarities = []\n",
    "    for word1, word2 in word_pairs:\n",
    "        if word1 in word2index and word2 in word2index:\n",
    "            word1_idx = torch.LongTensor([word2index[word1]])\n",
    "            word2_idx = torch.LongTensor([word2index[word2]])\n",
    "            \n",
    "            word1_embed = model.embedding_v(word1_idx)\n",
    "            word2_embed = model.embedding_v(word2_idx)\n",
    "            \n",
    "            # Cosine similarity\n",
    "            sim = F.cosine_similarity(word1_embed, word2_embed, dim=1).item()\n",
    "            similarities.append(sim)\n",
    "        else:\n",
    "            similarities.append(0.0)  # Assign 0 if either word is out of vocabulary\n",
    "    \n",
    "    return similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(human_scores, model_scores):\n",
    "    # Spearman correlation\n",
    "    spearman_corr, _ = spearmanr(human_scores, model_scores)\n",
    "    \n",
    "    # Mean Squared Error\n",
    "    mse = np.mean((np.array(human_scores) - np.array(model_scores)) ** 2)\n",
    "    \n",
    "    return spearman_corr, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage\n",
    "all_spearman_corrs = []\n",
    "all_mses = []\n",
    "\n",
    "filepaths = [\n",
    "    'wordsim_relatedness_goldstandard.txt',\n",
    "    'wordsim_similarity_goldstandard.txt',\n",
    "    'wordsim353_agreed.txt',\n",
    "    'wordsim353_annotator1.txt',\n",
    "    'wordsim353_annotator2.txt',\n",
    "]\n",
    "\n",
    "for filepath in filepaths:\n",
    "    # Parse the similarity dataset\n",
    "    word_pairs, human_scores = parse_similarity_file(filepath)\n",
    "    \n",
    "    # Compute model similarities\n",
    "    model_scores = compute_model_similarity(model, word2index, word_pairs)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    spearman_corr, mse = calculate_metrics(human_scores, model_scores)\n",
    "    all_spearman_corrs.append(spearman_corr)\n",
    "    all_mses.append(mse)\n",
    "    \n",
    "    print(f\"File: {filepath}\")\n",
    "    print(f\"Spearman Correlation: {spearman_corr:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average metrics across all files\n",
    "avg_spearman_corr = np.mean(all_spearman_corrs)\n",
    "avg_mse = np.mean(all_mses)\n",
    "\n",
    "print(f\"Average Spearman Correlation: {avg_spearman_corr:.4f}\")\n",
    "print(f\"Average MSE: {avg_mse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
